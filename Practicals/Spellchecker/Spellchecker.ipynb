{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BaPKXJ2tiQem"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('big.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('speling')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1z6FUpJLiWJB",
        "outputId": "028b08fc-4ab6-4e81-d9af-e0a2f7c1b219"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spelling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('korrectud')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EMxnMm0SijZF",
        "outputId": "42ee049e-70d4-44be-b5e5-d8c887db8ee0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'corrected'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unit_tests():\n",
        "    assert correction('speling') == 'spelling'              # insert\n",
        "    assert correction('korrectud') == 'corrected'           # replace 2\n",
        "    assert correction('bycycle') == 'bicycle'               # replace\n",
        "    assert correction('inconvient') == 'inconvenient'       # insert 2\n",
        "    assert correction('arrainged') == 'arranged'            # delete\n",
        "    assert correction('peotry') =='poetry'                  # transpose\n",
        "    assert correction('peotryy') =='poetry'                 # transpose + delete\n",
        "    assert correction('word') == 'word'                     # known\n",
        "    assert correction('quintessential') == 'quintessential' # unknown\n",
        "    assert words('This is a TEST.') == ['this', 'is', 'a', 'test']\n",
        "    assert Counter(words('This is a test. 123; A TEST this is.')) == (\n",
        "           Counter({'123': 1, 'a': 2, 'is': 2, 'test': 2, 'this': 2}))\n",
        "    assert len(WORDS) == 32198\n",
        "    assert sum(WORDS.values()) == 1115585\n",
        "    assert WORDS.most_common(10) == [('the', 79809),\n",
        " ('of', 40024),\n",
        " ('and', 38312),\n",
        " ('to', 28765),\n",
        " ('in', 22023),\n",
        " ('a', 21124),\n",
        " ('that', 12512),\n",
        " ('he', 12401),\n",
        " ('was', 11410),\n",
        " ('it', 10681)]\n",
        "    assert WORDS['the'] == 79809\n",
        "    assert P('quintessential') == 0\n",
        "    assert 0.07 < P('the') < 0.08\n",
        "    return 'unit_tests pass'\n",
        "\n",
        "def spelltest(tests, verbose=False):\n",
        "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
        "    import time\n",
        "    start = time.process_time()\n",
        "    good, unknown = 0, 0\n",
        "    n = len(tests)\n",
        "    for right, wrong in tests:\n",
        "        w = correction(wrong)\n",
        "        good += (w == right)\n",
        "        if w != right:\n",
        "            unknown += (right not in WORDS)\n",
        "            if verbose:\n",
        "                print('correction({}) => {} ({}); expected {} ({})'\n",
        "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
        "    dt = time.process_time() - start\n",
        "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
        "          .format(good / n, n, unknown / n, n / dt))\n",
        "    \n",
        "def Testset(lines):\n",
        "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
        "    return [(right, wrong)\n",
        "            for (right, wrongs) in (line.split(':') for line in lines)\n",
        "            for wrong in wrongs.split()]"
      ],
      "metadata": {
        "id": "CRWCdFfqim39"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unit_tests())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZd1RV1Zi0Wd",
        "outputId": "7f3682f3-eeb1-40df-e7ea-94f1569e24da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unit_tests pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spelltest(Testset(open('spell-testset1.txt'))) # Development set\n",
        "spelltest(Testset(open('spell-testset2.txt'))) # Final test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jfap23kok0",
        "outputId": "8605fdcf-a649-4dbb-d31f-f1daa32f0534"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75% of 270 correct (6% unknown) at 39 words per second \n",
            "75% of 270 correct (6% unknown) at 40 words per second \n"
          ]
        }
      ]
    }
  ]
}